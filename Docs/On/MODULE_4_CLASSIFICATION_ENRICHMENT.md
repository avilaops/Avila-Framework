# üß† M√ìDULO 4 - CLASSIFICA√á√ÉO INTELIGENTE & ENRIQUECIMENTO

## Sistema de Categoriza√ß√£o, Insights e Otimiza√ß√£o Autom√°tica

**Vers√£o:** 1.0
**Data:** 2025-11-10
**Posi√ß√£o no Pipeline:** Ap√≥s M√≥dulo 3 (Processamento Sem√¢ntico)

---

## üéØ OBJETIVO DO M√ìDULO

**Transformar dados brutos em conhecimento acion√°vel atrav√©s de:**

1. **Classifica√ß√£o Multi-Dimensional** - Categorizar documentos em 15+ dimens√µes
2. **Detec√ß√£o de Oportunidades** - Identificar economia de custos, otimiza√ß√µes, melhorias
3. **Enriquecimento Contextual** - Adicionar metadados, tags, relacionamentos
4. **Gera√ß√£o de Insights** - Criar recomenda√ß√µes pr√°ticas e alertas
5. **Prioriza√ß√£o Inteligente** - Ordenar a√ß√µes por impacto/urg√™ncia

---

## üìä TAXONOMIA DE CLASSIFICA√á√ÉO

### **Dimens√£o 1: TIPO DE RECURSO**

```python
RESOURCE_TYPES = {
    "SERVIDOR": {
        "description": "Servidores, VMs, inst√¢ncias cloud",
        "subcategorias": [
            "Azure VM",
            "AWS EC2",
            "On-Premise",
            "Container (Docker/K8s)",
            "Serverless (Functions)"
        ],
        "palavras_chave": ["servidor", "vm", "instance", "ec2", "virtual machine"]
    },

    "BANCO_DE_DADOS": {
        "description": "Databases, data warehouses, caches",
        "subcategorias": [
            "SQL (PostgreSQL, MySQL, SQL Server)",
            "NoSQL (MongoDB, Cosmos DB, DynamoDB)",
            "Cache (Redis, Memcached)",
            "Data Warehouse (Snowflake, BigQuery)",
            "Vector DB (Qdrant, Pinecone)"
        ],
        "palavras_chave": ["database", "db", "sql", "nosql", "cache"]
    },

    "ARMAZENAMENTO": {
        "description": "Storage, buckets, file systems",
        "subcategorias": [
            "Blob Storage (Azure/S3)",
            "File Share (NFS/SMB)",
            "Archive (Glacier/Cool tier)",
            "CDN (CloudFront/Azure CDN)"
        ],
        "palavras_chave": ["storage", "bucket", "blob", "s3", "file"]
    },

    "REDE": {
        "description": "VPNs, Load Balancers, DNS, Firewalls",
        "subcategorias": [
            "Load Balancer",
            "VPN Gateway",
            "DNS Zone",
            "Firewall/NSG",
            "CDN"
        ],
        "palavras_chave": ["network", "vpn", "load balancer", "dns", "firewall"]
    },

    "SERVICO_GERENCIADO": {
        "description": "PaaS, SaaS, managed services",
        "subcategorias": [
            "API Management",
            "Logic Apps / Step Functions",
            "Event Hub / EventBridge",
            "AI Services (OpenAI, Cognitive)",
            "Monitoring (App Insights, CloudWatch)"
        ],
        "palavras_chave": ["managed", "paas", "saas", "api", "event"]
    },

    "LICENCA_SOFTWARE": {
        "description": "Licenses, subscriptions, tools",
        "subcategorias": [
            "IDEs (VS Code, IntelliJ)",
            "Collaboration (Slack, Teams, Notion)",
            "Design (Figma, Adobe)",
            "Development (GitHub, GitLab, Jira)",
            "Security (1Password, Okta)"
        ],
        "palavras_chave": ["license", "subscription", "saas", "tool", "software"]
    },

    "CONHECIMENTO": {
        "description": "Docs, tutorials, estudos, research",
        "subcategorias": [
            "Tutorial/How-to",
            "Arquitetura/Design",
            "Pesquisa/Research",
            "Troubleshooting/Debug",
            "Best Practices"
        ],
        "palavras_chave": ["tutorial", "how to", "guide", "documentation", "study"]
    },

    "CODIGO": {
        "description": "Source code, scripts, configs",
        "subcategorias": [
            "Backend (Python, Node, Java)",
            "Frontend (React, Vue, Angular)",
            "Mobile (React Native, Flutter)",
            "Infrastructure (Terraform, CloudFormation)",
            "Scripts (Bash, PowerShell, Python)"
        ],
        "palavras_chave": ["code", "script", "function", "class", "import"]
    }
}
```

---

### **Dimens√£o 2: OPORTUNIDADES DE ECONOMIA**

```python
COST_OPPORTUNITIES = {
    "RIGHTSIZING": {
        "description": "Recursos super-dimensionados (muito CPU/RAM/Storage)",
        "impacto_medio": "30-50% economia",
        "deteccao": {
            "servidores": "CPU < 20% por 7+ dias ‚Üí downsize",
            "storage": "< 50% utilizado por 30+ dias ‚Üí tier mais barato",
            "database": "IOPS < 30% provisionado ‚Üí reduzir throughput"
        },
        "exemplo": """
        # Detectado:
        Azure VM: Standard_D8s_v3 (8 vCPUs, 32GB RAM)
        ‚îî‚îÄ CPU avg: 12% (√∫ltimos 30 dias)
        ‚îî‚îÄ RAM avg: 8GB (25% uso)
        ‚îî‚îÄ Custo: $280/m√™s

        # Recomenda√ß√£o:
        Migrar para: Standard_D4s_v3 (4 vCPUs, 16GB RAM)
        ‚îî‚îÄ Comporta carga atual com folga (50% CPU, 50% RAM)
        ‚îî‚îÄ Custo: $140/m√™s
        ‚îî‚îÄ üí∞ Economia: $140/m√™s = $1,680/ano

        # Confian√ßa: 95% (padr√£o est√°vel 90 dias)
        # Risco: BAIXO (CPU/RAM sobra 2x)
        # A√ß√£o: Agendar migra√ß√£o fora de hor√°rio comercial
        """
    },

    "RESERVED_INSTANCES": {
        "description": "Recursos 24/7 sem commitment (pague menos com reserved)",
        "impacto_medio": "30-72% economia",
        "deteccao": {
            "criterio": "Uptime > 80% nos √∫ltimos 90 dias",
            "tipos": ["VMs", "Databases", "App Services"]
        },
        "exemplo": """
        # Detectado:
        PostgreSQL Database (General Purpose, 4 vCores)
        ‚îî‚îÄ Uptime: 99.8% (√∫ltimos 90 dias)
        ‚îî‚îÄ Custo Pay-as-you-go: $250/m√™s

        # Recomenda√ß√£o:
        Reserved Instance (1 ano, pagamento mensal)
        ‚îî‚îÄ Custo: $162/m√™s
        ‚îî‚îÄ üí∞ Economia: $88/m√™s = $1,056/ano (35% desconto)

        Reserved Instance (3 anos, upfront)
        ‚îî‚îÄ Custo: $110/m√™s
        ‚îî‚îÄ üí∞ Economia: $140/m√™s = $1,680/ano (56% desconto)

        # Recomenda√ß√£o: 1 ano (mais flex√≠vel)
        # Risco: BAIXO (workload est√°vel)
        # Payback: Imediato
        """
    },

    "STORAGE_TIERING": {
        "description": "Dados raramente acessados em tier caro (hot storage)",
        "impacto_medio": "50-90% economia em storage",
        "deteccao": {
            "hot_to_cool": "N√£o acessado por 30+ dias ‚Üí Cool tier",
            "cool_to_archive": "N√£o acessado por 90+ dias ‚Üí Archive tier"
        },
        "exemplo": """
        # Detectado:
        Azure Blob Storage: 2TB em Hot tier
        ‚îî‚îÄ An√°lise de acesso (√∫ltimos 90 dias):
            - 200GB: acessados semanalmente (manter Hot)
            - 800GB: acessados 1x/m√™s (mover Cool)
            - 1TB: n√£o acessados (mover Archive)

        # Custos Atuais:
        2TB Hot: $40/TB/m√™s = $80/m√™s

        # Custos Otimizados:
        200GB Hot: $40/TB/m√™s = $8/m√™s
        800GB Cool: $10/TB/m√™s = $8/m√™s
        1TB Archive: $2/TB/m√™s = $2/m√™s
        Total: $18/m√™s

        üí∞ Economia: $62/m√™s = $744/ano (77% redu√ß√£o!)

        # Implementa√ß√£o:
        - Lifecycle policy autom√°tica (Azure/AWS)
        - Hot ‚Üí Cool ap√≥s 30 dias sem acesso
        - Cool ‚Üí Archive ap√≥s 90 dias

        # Risco: ZERO (dados n√£o perdidos, apenas lat√™ncia +ms se acessar)
        """
    },

    "ZOMBIE_RESOURCES": {
        "description": "Recursos inativos/√≥rf√£os cobrando desnecessariamente",
        "impacto_medio": "100% economia (remover)",
        "deteccao": {
            "vm_stopped": "VM parada > 30 dias (mas cobrando disk)",
            "disk_unattached": "Discos n√£o conectados a nada",
            "ip_unassigned": "IPs p√∫blicos n√£o associados",
            "snapshot_old": "Snapshots > 1 ano"
        },
        "exemplo": """
        # Detectado (scan autom√°tico):

        1Ô∏è‚É£ VM "dev-test-old" (parada h√° 120 dias)
           ‚îî‚îÄ Disk: 256GB Premium SSD
           ‚îî‚îÄ Custo: $50/m√™s (mesmo parada!)
           ‚îî‚îÄ üí∞ Economia: DELETE ‚Üí $50/m√™s

        2Ô∏è‚É£ 8x Discos n√£o conectados
           ‚îî‚îÄ Total: 2TB
           ‚îî‚îÄ Custo: $200/m√™s
           ‚îî‚îÄ üí∞ Economia: DELETE ‚Üí $200/m√™s

        3Ô∏è‚É£ 12x IPs p√∫blicos n√£o associados
           ‚îî‚îÄ Custo: $36/m√™s ($3 cada)
           ‚îî‚îÄ üí∞ Economia: RELEASE ‚Üí $36/m√™s

        4Ô∏è‚É£ 45x Snapshots > 1 ano (n√£o usados)
           ‚îî‚îÄ Total: 500GB
           ‚îî‚îÄ Custo: $25/m√™s
           ‚îî‚îÄ üí∞ Economia: DELETE ‚Üí $25/m√™s

        TOTAL: $311/m√™s = $3,732/ano üí∏

        # A√ß√£o:
        1. Notificar owners (7 dias para responder)
        2. Se n√£o responder ‚Üí auto-delete
        3. Backup metadata antes (recuper√°vel se erro)
        """
    },

    "SPOT_INSTANCES": {
        "description": "Workloads tolerantes a interrup√ß√£o em inst√¢ncias regulares",
        "impacto_medio": "60-90% economia",
        "deteccao": {
            "candidatos": [
                "Batch processing",
                "CI/CD pipelines",
                "Dev/test environments",
                "Data processing (n√£o real-time)"
            ]
        },
        "exemplo": """
        # Detectado:
        Nightly ETL pipeline (roda 2-4h, 1x/dia)
        ‚îî‚îÄ VM: Standard_D16s_v3
        ‚îî‚îÄ Custo atual: $600/m√™s (pay-as-you-go)

        # Recomenda√ß√£o:
        Azure Spot VM (mesma spec)
        ‚îî‚îÄ Custo: $60-120/m√™s (80-90% desconto)
        ‚îî‚îÄ üí∞ Economia: ~$500/m√™s = $6,000/ano

        # Trade-off:
        - Pode ser interrompido (low probability 2-4am)
        - Implementar checkpointing (retomar de onde parou)
        - Fallback: se spot indispon√≠vel, usar regular (1 vez/m√™s)

        # ROI: Mesmo com 10% fallback, economia de 75%
        """
    },

    "LICENCA_SUBUTILIZADA": {
        "description": "Licen√ßas pagas mas n√£o usadas ativamente",
        "impacto_medio": "Economia vari√°vel (remove ou downgrade)",
        "deteccao": {
            "criterios": [
                "√öltimo login > 60 dias",
                "Uso < 10% features (ex: Jira s√≥ para ver tickets)",
                "Duplica√ß√£o (mesmo user em 2 tools similares)"
            ]
        },
        "exemplo": """
        # Detectado:

        1Ô∏è‚É£ GitHub Copilot Business (50 licen√ßas)
           ‚îî‚îÄ Uso ativo: 32 users (√∫ltimos 30 dias)
           ‚îî‚îÄ 18 licen√ßas sem uso
           ‚îî‚îÄ Custo: $19/user/m√™s √ó 18 = $342/m√™s
           ‚îî‚îÄ üí∞ Economia: Remove 18 ‚Üí $342/m√™s

        2Ô∏è‚É£ Jira (100 licen√ßas)
           ‚îî‚îÄ An√°lise de uso:
               - 40 users: uso di√°rio (devs)
               - 30 users: 1x/semana (PMs, designers)
               - 30 users: last login > 90 dias
           ‚îî‚îÄ Custo: $14/user √ó 30 = $420/m√™s
           ‚îî‚îÄ üí∞ Economia: Remove 30 ‚Üí $420/m√™s

        3Ô∏è‚É£ Figma Professional (duplicado com Adobe XD)
           ‚îî‚îÄ 5 designers usando ambos
           ‚îî‚îÄ Consolidar: migrar para Figma (mais usado)
           ‚îî‚îÄ Cancelar Adobe XD: $55/user √ó 5 = $275/m√™s
           ‚îî‚îÄ üí∞ Economia: $275/m√™s

        TOTAL: $1,037/m√™s = $12,444/ano

        # Processo:
        1. Email para users inativos (migra√ß√£o/cancelamento)
        2. Offboarding autom√°tico (30 dias sem resposta)
        3. Review trimestral de uso
        """
    }
}
```

---

### **Dimens√£o 3: OPORTUNIDADES DE CONHECIMENTO**

```python
KNOWLEDGE_OPPORTUNITIES = {
    "PATTERN_LEARNING": {
        "description": "Identificar padr√µes recorrentes para criar playbooks",
        "deteccao": {
            "troubleshooting_repetido": "Mesmo erro resolvido 3+ vezes ‚Üí criar runbook",
            "pergunta_frequente": "Mesma d√∫vida em 5+ conversas Copilot ‚Üí FAQ",
            "codigo_duplicado": "Fun√ß√£o similar em 3+ repos ‚Üí criar biblioteca"
        },
        "exemplo": """
        # Detectado (clustering de Copilot history):

        Padr√£o: "Como conectar Azure SQL com Python?"
        ‚îî‚îÄ Apareceu em: 12 conversas (√∫ltimos 60 dias)
        ‚îî‚îÄ Time gasto: ~45min/vez (pesquisa + tentativa/erro)
        ‚îî‚îÄ Custo total: 12 √ó 45min = 9h desperdi√ßadas

        # A√ß√£o Autom√°tica:
        1. GPT-4 gera snippet can√¥nico (melhor das 12 solu√ß√µes)
        2. Adiciona ao Obsidian: "snippets/azure-sql-python.md"
        3. Indexa no vector DB (alta prioridade)
        4. Pr√≥xima vez: Copilot sugere snippet em 5s

        # ROI:
        - Economia: 45min ‚Üí 5s = 99.8% redu√ß√£o
        - Knowledge compound: outros devs usam snippet
        - Pr√≥ximo ano: ~50 usos √ó 45min = 37.5h economizadas
        """
    },

    "SKILL_GAP_DETECTION": {
        "description": "Identificar √°reas onde time tem dificuldade",
        "deteccao": {
            "copilot_struggles": "Muitas itera√ß√µes para resolver tarefa",
            "terminal_errors": "Mesmos erros repetidos",
            "google_searches": "Pesquisas similares recorrentes"
        },
        "exemplo": """
        # Detectado (an√°lise ActivityWatch + Terminal):

        Dev: Jo√£o Silva
        ‚îî‚îÄ Comandos Git: 40% taxa de erro
            - "git rebase" ‚Üí erro (5x esta semana)
            - "git cherry-pick" ‚Üí erro (3x)
            - Undo/reset: 15 tentativas

        ‚îî‚îÄ Tempo gasto debugging Git: 4h/semana
        ‚îî‚îÄ Google: "git rebase conflict", "git undo commit" (recorrente)

        # Insight:
        Skill gap: Git workflows avan√ßados

        # Recomenda√ß√£o Autom√°tica:
        üìö Sugerir treinamento:
           - Curso: "Git Pro" (Udemy, 6h)
           - Custo: $20
           - ROI: 4h/semana √ó 48 semanas = 192h/ano
           - Valor: 192h √ó $75/h = $14,400
           - Payback: 1 dia

        üìÑ Criar cheat sheet personalizado:
           - Comandos que Jo√£o mais usa + erra
           - Obsidian: "git-cheatsheet-jo√£o.md"
           - Pin no VS Code sidebar

        ü§ñ Copilot auto-suggest:
           - Detecta comando Git ‚Üí previne erros comuns
           - "‚ö†Ô∏è Cuidado: voc√™ est√° em branch main. Criar feature branch primeiro?"
        """
    },

    "BEST_PRACTICE_EXTRACTION": {
        "description": "Capturar solu√ß√µes elegantes para reutilizar",
        "deteccao": {
            "code_quality": "Fun√ß√£o com alta coes√£o, baixo acoplamento",
            "performance_win": "Otimiza√ß√£o que melhorou 10x+",
            "security_fix": "Corre√ß√£o de vulnerabilidade"
        },
        "exemplo": """
        # Detectado (git diff analysis):

        Commit: "Otimizar query de relat√≥rios - 45s ‚Üí 2s"
        Author: Ana Costa
        File: reports/analytics.py

        Diff:
        - query = db.query(...).all()  # carregava tudo na RAM
        + query = db.query(...).yield_per(1000)  # streaming

        Impact: -95% lat√™ncia, -90% RAM

        # A√ß√£o Autom√°tica:
        1. Extrair padr√£o: "Use yield_per() para queries grandes"
        2. Criar best practice doc:
           - Antes/depois
           - Quando aplicar (N > 10k rows)
           - Code snippet
        3. Adicionar √† knowledge base
        4. Lint rule: detectar .all() em queries grandes ‚Üí sugerir yield_per()

        # Dissemina√ß√£o:
        - Slack: "üí° Ana otimizou query em 95%! Veja como: [link]"
        - Code review bot: cita best practice quando relevante
        - Onboarding: adicionado a "Python Performance Guide"
        """
    },

    "DEPENDENCY_RISK": {
        "description": "Detectar depend√™ncias cr√≠ticas concentradas em 1 pessoa",
        "deteccao": {
            "single_owner": "1 pessoa fez 90%+ commits em m√≥dulo cr√≠tico",
            "tribal_knowledge": "Conhecimento n√£o documentado"
        },
        "exemplo": """
        # Detectado (git blame + org chart):

        M√≥dulo: payment_processing/
        ‚îî‚îÄ Commits: 95% por Carlos (√∫nico dev que entende)
        ‚îî‚îÄ Documenta√ß√£o: 0 READMEs, 0 docstrings
        ‚îî‚îÄ Criticidade: HIGH (processa $500k/m√™s)

        Risco: Se Carlos sair/f√©rias ‚Üí time stuck

        # A√ß√£o Autom√°tica:
        1. üö® Alert para CTO: "Bus factor = 1 em m√≥dulo cr√≠tico"

        2. üìù Criar documenta√ß√£o obrigat√≥ria:
           - GPT-4 gera draft de README (baseado em c√≥digo)
           - Carlos revisa/aprova (30min vs 4h manual)
           - Adiciona: arquitetura, flows, edge cases

        3. üë• Knowledge transfer:
           - Pair programming: Carlos + 2 devs (4h)
           - Gravar walkthrough em v√≠deo (15min)
           - Indexar no knowledge base

        4. üîÑ Code rotation:
           - Pr√≥ximas features: outro dev implementa (Carlos revisa)
           - Goal: 3 devs confort√°veis em 3 meses

        # M√©trica:
        Bus factor: 1 ‚Üí 3 (risco -66%)
        """
    }
}
```

---

### **Dimens√£o 4: TIPO DE INSIGHT**

```python
INSIGHT_TYPES = {
    "ALERTA_URGENTE": {
        "prioridade": "P0 - A√ß√£o imediata",
        "sla_resposta": "24h",
        "exemplos": [
            "Servidor com 95%+ CPU por 6h+ (risco de crash)",
            "CVE cr√≠tico detectado em depend√™ncia (exploitable)",
            "Custo mensal 50%+ acima do or√ßado (leak de recursos)",
            "Backup falhou 3+ dias consecutivos (risco de perda)"
        ],
        "notificacao": ["Email", "Slack", "SMS", "PagerDuty"]
    },

    "OPORTUNIDADE_ALTO_IMPACTO": {
        "prioridade": "P1 - Agendar esta semana",
        "sla_resposta": "7 dias",
        "exemplos": [
            "Economia potencial > $1k/m√™s (rightsizing, reserved)",
            "Automa√ß√£o que economiza 10h+/semana",
            "Security fix (n√£o cr√≠tico mas importante)",
            "Performance win > 50% (user experience)"
        ],
        "notificacao": ["Email", "Slack", "Dashboard"]
    },

    "MELHORIA_CONTINUA": {
        "prioridade": "P2 - Incluir no pr√≥ximo sprint",
        "sla_resposta": "30 dias",
        "exemplos": [
            "Refactoring (reduzir technical debt)",
            "Documenta√ß√£o faltando",
            "Test coverage < 70%",
            "Dependency update (non-breaking)"
        ],
        "notificacao": ["Dashboard", "Weekly digest"]
    },

    "APRENDIZADO": {
        "prioridade": "P3 - Knowledge sharing",
        "sla_resposta": "Cont√≠nuo",
        "exemplos": [
            "Padr√£o interessante descoberto",
            "Nova tecnologia/lib √∫til",
            "Case study de sucesso",
            "Erro comum + solu√ß√£o"
        ],
        "notificacao": ["Slack #learnings", "Monthly newsletter"]
    }
}
```

---

## üîß IMPLEMENTA√á√ÉO T√âCNICA

### **Pipeline de Classifica√ß√£o**

```python
import openai
import json
from typing import Dict, List
from datetime import datetime, timedelta

class Module4Classifier:
    """
    Classificador inteligente multi-dimensional
    """

    def __init__(self, config):
        self.config = config
        self.openai_client = openai.Client(api_key=config['openai_api_key'])

    def classify_document(self, doc: Dict) -> Dict:
        """
        Classifica documento em todas as dimens√µes
        """
        classifications = {
            "resource_type": self._classify_resource_type(doc),
            "cost_opportunities": self._detect_cost_opportunities(doc),
            "knowledge_opportunities": self._detect_knowledge_opportunities(doc),
            "insights": self._generate_insights(doc),
            "enrichments": self._enrich_metadata(doc),
            "priority_score": 0  # calculado depois
        }

        # Calcular prioridade final
        classifications['priority_score'] = self._calculate_priority(classifications)

        return classifications

    def _classify_resource_type(self, doc: Dict) -> List[str]:
        """
        Detecta tipo de recurso via GPT-4 + keywords
        """
        # 1. Tentativa r√°pida: keyword matching
        content_lower = doc['content'].lower()

        matched_types = []
        for resource_type, config in RESOURCE_TYPES.items():
            for keyword in config['palavras_chave']:
                if keyword in content_lower:
                    matched_types.append(resource_type)
                    break

        # 2. Se amb√≠guo ou vazio: usar GPT-4
        if len(matched_types) != 1:
            prompt = f"""
Classifique este documento em UMA categoria principal:

Categorias: {', '.join(RESOURCE_TYPES.keys())}

Documento:
---
{doc['content'][:1000]}
---

Retorne apenas o nome da categoria (ex: "SERVIDOR").
"""
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )

            gpt_category = response.choices[0].message.content.strip()
            matched_types = [gpt_category] if gpt_category in RESOURCE_TYPES else matched_types

        return matched_types

    def _detect_cost_opportunities(self, doc: Dict) -> List[Dict]:
        """
        Detecta oportunidades de economia de custos
        """
        opportunities = []

        # 1. RIGHTSIZING (baixa utiliza√ß√£o de recursos)
        if self._is_azure_resource(doc):
            metrics = self._extract_metrics(doc)

            if metrics.get('cpu_avg') and metrics['cpu_avg'] < 20:
                saving = self._calculate_rightsizing_saving(metrics)
                opportunities.append({
                    "type": "RIGHTSIZING",
                    "current_cost": metrics.get('monthly_cost', 0),
                    "potential_saving": saving,
                    "confidence": 0.95 if self._has_stable_pattern(metrics) else 0.70,
                    "action": f"Downsize de {metrics['current_sku']} para {metrics['recommended_sku']}",
                    "risk": "BAIXO" if saving['percentage'] < 50 else "M√âDIO"
                })

        # 2. RESERVED INSTANCES (uptime alto)
        if self._has_high_uptime(doc):
            ri_saving = self._calculate_reserved_saving(doc)
            opportunities.append({
                "type": "RESERVED_INSTANCES",
                "current_cost": ri_saving['payg_cost'],
                "potential_saving": ri_saving['saving'],
                "confidence": 0.90,
                "action": f"Comprar Reserved Instance ({ri_saving['term']})",
                "risk": "BAIXO"
            })

        # 3. ZOMBIE RESOURCES (inativos)
        if self._is_zombie_resource(doc):
            opportunities.append({
                "type": "ZOMBIE_RESOURCES",
                "current_cost": doc.get('monthly_cost', 50),
                "potential_saving": {"amount": doc.get('monthly_cost', 50), "percentage": 100},
                "confidence": 0.99,
                "action": "DELETE (recurso inativo h√° 90+ dias)",
                "risk": "ZERO"
            })

        # 4. STORAGE TIERING
        if doc.get('resource_type') == 'ARMAZENAMENTO':
            tiering = self._analyze_storage_access_pattern(doc)
            if tiering['saving']['amount'] > 10:
                opportunities.append({
                    "type": "STORAGE_TIERING",
                    "current_cost": tiering['current_cost'],
                    "potential_saving": tiering['saving'],
                    "confidence": 0.85,
                    "action": f"Mover {tiering['gb_to_cool']}GB para Cool, {tiering['gb_to_archive']}GB para Archive",
                    "risk": "ZERO"
                })

        return opportunities

    def _detect_knowledge_opportunities(self, doc: Dict) -> List[Dict]:
        """
        Detecta oportunidades de aprendizado e otimiza√ß√£o
        """
        opportunities = []

        # 1. PADR√ïES REPETIDOS (criar playbook)
        if self._is_troubleshooting_doc(doc):
            similar_docs = self._find_similar_issues(doc)

            if len(similar_docs) >= 3:
                opportunities.append({
                    "type": "PATTERN_LEARNING",
                    "pattern": doc.get('issue_title', 'Unknown'),
                    "occurrences": len(similar_docs),
                    "time_wasted": len(similar_docs) * 45,  # minutos
                    "action": "Criar runbook autom√°tico",
                    "impact": "HIGH"
                })

        # 2. SKILL GAPS (treinar time)
        if self._has_error_pattern(doc):
            skill_gap = self._analyze_skill_gap(doc)
            opportunities.append({
                "type": "SKILL_GAP_DETECTION",
                "skill": skill_gap['skill_name'],
                "developer": skill_gap['developer'],
                "error_rate": skill_gap['error_rate'],
                "time_wasted_weekly": skill_gap['hours_wasted'],
                "recommended_training": skill_gap['training_suggestions'],
                "impact": "MEDIUM"
            })

        # 3. BEST PRACTICES (documentar e disseminar)
        if self._is_performance_improvement(doc):
            opportunities.append({
                "type": "BEST_PRACTICE_EXTRACTION",
                "improvement": doc.get('title'),
                "impact_metrics": doc.get('metrics', {}),
                "author": doc.get('author'),
                "action": "Documentar e compartilhar com time",
                "impact": "HIGH"
            })

        # 4. DEPENDENCY RISK (bus factor)
        if self._has_single_point_of_knowledge(doc):
            opportunities.append({
                "type": "DEPENDENCY_RISK",
                "module": doc.get('module_name'),
                "owner": doc.get('primary_author'),
                "commit_percentage": doc.get('ownership_percentage', 0),
                "criticality": doc.get('business_criticality', 'MEDIUM'),
                "action": "Knowledge transfer + documenta√ß√£o",
                "impact": "HIGH"
            })

        return opportunities

    def _enrich_metadata(self, doc: Dict) -> Dict:
        """
        Adiciona metadados enriquecidos ao documento
        """
        enrichments = {
            "tags_auto": [],
            "relacionamentos": [],
            "contexto_business": {},
            "metricas_tecnicas": {},
            "owner_sugerido": None,
            "expiration_date": None
        }

        # Tags autom√°ticas (via NER + keywords)
        enrichments['tags_auto'] = self._extract_tags(doc)

        # Relacionamentos (documentos similares)
        enrichments['relacionamentos'] = self._find_related_docs(doc)

        # Contexto de neg√≥cio (qual setor/projeto)
        enrichments['contexto_business'] = self._infer_business_context(doc)

        # M√©tricas t√©cnicas (custo, performance, etc)
        enrichments['metricas_tecnicas'] = self._extract_metrics(doc)

        # Owner sugerido (quem deve cuidar disso?)
        enrichments['owner_sugerido'] = self._suggest_owner(doc)

        # Data de expira√ß√£o (doc tempor√°rio?)
        if self._is_temporary_doc(doc):
            enrichments['expiration_date'] = self._calculate_expiration(doc)

        return enrichments

    def _generate_insights(self, doc: Dict) -> List[Dict]:
        """
        Gera insights acion√°veis via GPT-4
        """
        # Preparar contexto para GPT-4
        context = {
            "doc_title": doc.get('title'),
            "doc_type": doc.get('type'),
            "resource_types": self._classify_resource_type(doc),
            "cost_opportunities": self._detect_cost_opportunities(doc),
            "knowledge_opportunities": self._detect_knowledge_opportunities(doc),
            "metrics": self._extract_metrics(doc)
        }

        prompt = f"""
Voc√™ √© um consultor de TI analisando documentos de uma empresa.

Documento: {doc.get('title')}
Tipo: {doc.get('type')}
Conte√∫do (preview): {doc['content'][:500]}

Contexto adicional:
{json.dumps(context, indent=2)}

Gere 3-5 INSIGHTS ACION√ÅVEIS:
1. Cada insight deve ter: t√≠tulo, descri√ß√£o, a√ß√£o recomendada, impacto (LOW/MEDIUM/HIGH)
2. Focar em: economia de custos, otimiza√ß√£o, seguran√ßa, conhecimento
3. Ser espec√≠fico e pr√°tico (n√£o gen√©rico)

Formato JSON:
[
  {{
    "titulo": "...",
    "descricao": "...",
    "acao": "...",
    "impacto": "HIGH|MEDIUM|LOW",
    "prioridade": "P0|P1|P2|P3"
  }}
]
"""

        response = self.openai_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        insights = json.loads(response.choices[0].message.content)
        return insights.get('insights', [])

    def _calculate_priority(self, classifications: Dict) -> float:
        """
        Calcula score de prioridade (0-100)
        """
        score = 0

        # Peso 1: Economia de custos (0-40 pontos)
        total_saving = sum([
            opp.get('potential_saving', {}).get('amount', 0)
            for opp in classifications.get('cost_opportunities', [])
        ])
        score += min(40, total_saving / 100)  # $100 saving = 1 ponto

        # Peso 2: Insights de alto impacto (0-30 pontos)
        high_impact_insights = [
            ins for ins in classifications.get('insights', [])
            if ins.get('impacto') == 'HIGH'
        ]
        score += len(high_impact_insights) * 10

        # Peso 3: Urg√™ncia (0-30 pontos)
        if self._has_p0_alert(classifications):
            score += 30
        elif self._has_p1_opportunity(classifications):
            score += 20

        return min(100, score)

    # M√©todos auxiliares (detec√ß√£o)

    def _is_azure_resource(self, doc: Dict) -> bool:
        keywords = ['azure', 'vm', 'app service', 'sql database']
        return any(k in doc['content'].lower() for k in keywords)

    def _extract_metrics(self, doc: Dict) -> Dict:
        """Extrai m√©tricas via regex ou API calls"""
        # Implementa√ß√£o depende da fonte (Azure Monitor, AWS CloudWatch, etc)
        return {}

    def _has_stable_pattern(self, metrics: Dict) -> bool:
        """Verifica se padr√£o de uso √© est√°vel (90 dias)"""
        return metrics.get('days_monitored', 0) >= 90

    def _calculate_rightsizing_saving(self, metrics: Dict) -> Dict:
        """Calcula economia de downsize"""
        # L√≥gica de pricing Azure/AWS
        return {"amount": 140, "percentage": 50}

    def _has_high_uptime(self, doc: Dict) -> bool:
        """Detecta se recurso tem uptime alto (candidato a reserved)"""
        return doc.get('uptime_percentage', 0) > 80

    def _is_zombie_resource(self, doc: Dict) -> bool:
        """Detecta recurso inativo"""
        last_activity = doc.get('last_activity_days', 0)
        return last_activity > 90

    def _is_troubleshooting_doc(self, doc: Dict) -> bool:
        keywords = ['error', 'fix', 'troubleshoot', 'debug', 'resolved']
        return any(k in doc['title'].lower() for k in keywords)

    def _find_similar_issues(self, doc: Dict) -> List[Dict]:
        """Busca documentos similares no vector DB"""
        # Query vector DB com embedding do doc
        return []

    def _has_error_pattern(self, doc: Dict) -> bool:
        """Detecta padr√£o de erros repetidos"""
        return 'error' in doc.get('type', '').lower()

    def _analyze_skill_gap(self, doc: Dict) -> Dict:
        """Analisa gap de conhecimento"""
        return {
            "skill_name": "Git Advanced",
            "developer": doc.get('author'),
            "error_rate": 0.40,
            "hours_wasted": 4,
            "training_suggestions": ["Git Pro course (Udemy)"]
        }

    def _is_performance_improvement(self, doc: Dict) -> bool:
        keywords = ['optimize', 'improve', 'faster', '10x', 'performance']
        return any(k in doc['content'].lower() for k in keywords)

    def _has_single_point_of_knowledge(self, doc: Dict) -> bool:
        """Detecta conhecimento concentrado (bus factor 1)"""
        return doc.get('ownership_percentage', 0) > 90

    def _extract_tags(self, doc: Dict) -> List[str]:
        """Extrai tags via NER"""
        return []

    def _find_related_docs(self, doc: Dict) -> List[str]:
        """Busca docs relacionados"""
        return []

    def _infer_business_context(self, doc: Dict) -> Dict:
        """Infere contexto de neg√≥cio (setor, projeto)"""
        return {"setor": "Tecnologia", "projeto": "Plataforma"}

    def _suggest_owner(self, doc: Dict) -> str:
        """Sugere respons√°vel"""
        return doc.get('author', 'Unassigned')

    def _is_temporary_doc(self, doc: Dict) -> bool:
        """Detecta se doc √© tempor√°rio"""
        temp_keywords = ['temp', 'draft', 'wip', 'test']
        return any(k in doc['title'].lower() for k in temp_keywords)

    def _calculate_expiration(self, doc: Dict) -> str:
        """Calcula data de expira√ß√£o sugerida"""
        return (datetime.now() + timedelta(days=30)).isoformat()

    def _has_p0_alert(self, classifications: Dict) -> bool:
        return any(
            ins.get('prioridade') == 'P0'
            for ins in classifications.get('insights', [])
        )

    def _has_p1_opportunity(self, classifications: Dict) -> bool:
        return any(
            ins.get('prioridade') == 'P1'
            for ins in classifications.get('insights', [])
        )
```

---

## üìä OUTPUT DO M√ìDULO 4

### **Exemplo de Documento Classificado**

```json
{
  "document_id": "doc_12345",
  "original": {
    "title": "Azure VM Performance Analysis - Oct 2025",
    "source": "Obsidian Vault/Modulo 1/Azure CLI outputs",
    "created_at": "2025-10-15T10:30:00Z",
    "author": "Jo√£o Silva"
  },

  "classifications": {
    "resource_type": ["SERVIDOR"],
    "sub_types": ["Azure VM", "Windows Server 2022"],

    "cost_opportunities": [
      {
        "type": "RIGHTSIZING",
        "current_cost": 280,
        "potential_saving": {
          "amount": 140,
          "percentage": 50
        },
        "confidence": 0.95,
        "action": "Downsize de Standard_D8s_v3 para Standard_D4s_v3",
        "risk": "BAIXO",
        "implementation_time": "30min",
        "payback_period": "Imediato"
      },
      {
        "type": "RESERVED_INSTANCES",
        "current_cost": 140,
        "potential_saving": {
          "amount": 49,
          "percentage": 35
        },
        "confidence": 0.90,
        "action": "Comprar Reserved Instance (1 ano)",
        "risk": "BAIXO",
        "implementation_time": "5min"
      }
    ],

    "knowledge_opportunities": [
      {
        "type": "PATTERN_LEARNING",
        "pattern": "CPU utilization monitoring setup",
        "occurrences": 8,
        "time_wasted": 360,
        "action": "Criar runbook: Azure VM monitoring setup",
        "impact": "MEDIUM",
        "estimated_saving": "6h/m√™s"
      }
    ],

    "insights": [
      {
        "titulo": "Economia de $189/m√™s combinando rightsizing + reserved",
        "descricao": "VM est√° 50% subutilizada. Ap√≥s downsize, comprar reserved instance resulta em economia total de 67%.",
        "acao": "1) Agendar downsize (s√°bado 2am), 2) Comprar RI ap√≥s valida√ß√£o (1 semana)",
        "impacto": "HIGH",
        "prioridade": "P1",
        "estimated_roi": "$2,268/ano"
      },
      {
        "titulo": "Documentar processo de monitoring setup",
        "descricao": "Time configurou Azure Monitor 8x em VMs diferentes (mesmo processo). Criar template/runbook economiza 45min/vez.",
        "acao": "Jo√£o (autor original) cria runbook com GPT-4 assist (15min)",
        "impacto": "MEDIUM",
        "prioridade": "P2",
        "estimated_roi": "6h/ano economizadas"
      }
    ],

    "enrichments": {
      "tags_auto": [
        "azure",
        "virtual-machine",
        "windows-server",
        "performance-monitoring",
        "cost-optimization"
      ],

      "relacionamentos": [
        {
          "doc_id": "doc_98765",
          "title": "Azure Cost Report - Oct 2025",
          "similarity": 0.87,
          "relationship": "Este VM aparece no cost report como top 3 gastos"
        },
        {
          "doc_id": "doc_45678",
          "title": "Windows Server Patching Guide",
          "similarity": 0.72,
          "relationship": "Mesmo OS version, patching process aplic√°vel"
        }
      ],

      "contexto_business": {
        "setor": "Tecnologia",
        "projeto": "Production API Backend",
        "criticality": "HIGH",
        "sla": "99.9% uptime"
      },

      "metricas_tecnicas": {
        "cpu_avg_30d": 12,
        "ram_avg_30d": 25,
        "disk_io_avg": "low",
        "network_throughput": "medium",
        "uptime_90d": 99.8,
        "incident_count_90d": 0
      },

      "owner_sugerido": "Jo√£o Silva (Infrastructure Team)",
      "expiration_date": null
    },

    "priority_score": 78
  },

  "next_actions": [
    {
      "action": "Agendar downsize VM",
      "owner": "Jo√£o Silva",
      "due_date": "2025-11-17",
      "estimated_effort": "30min",
      "dependencies": ["Aprovar com stakeholders", "Backup antes"]
    },
    {
      "action": "Comprar Reserved Instance",
      "owner": "Jo√£o Silva",
      "due_date": "2025-11-24",
      "estimated_effort": "5min",
      "dependencies": ["Validar downsize funcionou"]
    },
    {
      "action": "Criar runbook de monitoring",
      "owner": "Jo√£o Silva",
      "due_date": "2025-11-30",
      "estimated_effort": "15min",
      "dependencies": []
    }
  ]
}
```

---

## üöÄ INTEGRA√á√ÉO COM M√ìDULOS ANTERIORES

```
M√≥dulo 1: COLETA
‚Üì
Documentos brutos
‚Üì
M√≥dulo 2: AGREGA√á√ÉO
‚Üì
Dados normalizados
‚Üì
M√≥dulo 3: PROCESSAMENTO SEM√ÇNTICO
‚Üì
Embeddings + Clusters + Knowledge Graph
‚Üì
M√≥dulo 4: CLASSIFICA√á√ÉO & ENRIQUECIMENTO ‚≠ê
‚Üì
‚îú‚îÄ Classifica√ß√µes multi-dimensionais
‚îú‚îÄ Oportunidades de economia
‚îú‚îÄ Oportunidades de conhecimento
‚îú‚îÄ Insights acion√°veis
‚îú‚îÄ Metadados enriquecidos
‚îî‚îÄ Prioriza√ß√£o inteligente
‚Üì
M√≥dulo 5: DECIS√ÉO (pr√≥ximo)
‚Üì
A√ß√µes autom√°ticas + Dashboards
```

---

## üìà M√âTRICAS DE SUCESSO DO M√ìDULO 4

```python
KPIs = {
    "CLASSIFICACAO": {
        "Accuracy": "> 90%",  # classifica√ß√£o correta de resource type
        "Coverage": "> 95%",  # % docs classificados (n√£o "unknown")
        "Latency": "< 5s/doc"  # tempo de processamento
    },

    "DETECCAO_OPORTUNIDADES": {
        "Precision": "> 80%",  # oportunidades sugeridas s√£o v√°lidas
        "Recall": "> 70%",  # captura maioria das oportunidades reais
        "False Positive Rate": "< 15%"  # n√£o sugerir mudan√ßas desnecess√°rias
    },

    "IMPACTO_BUSINESS": {
        "Economia Identificada": "> $10k/m√™s",
        "Tempo Economizado": "> 40h/m√™s",
        "Incidents Prevenidos": "> 5/m√™s"
    },

    "QUALIDADE_INSIGHTS": {
        "Actionability": "> 85%",  # insights levam a a√ß√µes concretas
        "User Satisfaction": "> 4.2/5",  # feedback do time
        "Time to Value": "< 7 dias"  # da detec√ß√£o √† implementa√ß√£o
    }
}
```

---

## üéì RESUMO EXECUTIVO

**M√≥dulo 4 = "C√©rebro" do Sistema**

**Entrada:**
- Documentos processados (embeddings, clusters, grafos)

**Processamento:**
- Classifica√ß√£o multi-dimensional (8 tipos de recursos)
- Detec√ß√£o de 6 tipos de oportunidades de custo
- Detec√ß√£o de 4 tipos de oportunidades de conhecimento
- Gera√ß√£o de insights via GPT-4
- Enriquecimento de metadados
- Prioriza√ß√£o inteligente (score 0-100)

**Sa√≠da:**
- Documentos enriquecidos com classifica√ß√µes, tags, relacionamentos
- Lista priorizada de oportunidades (economia + conhecimento)
- Insights acion√°veis (P0/P1/P2/P3)
- Next actions com owners e deadlines

**ROI Esperado:**
- üéØ **Economia:** $10-50k/m√™s identificados automaticamente
- ‚è±Ô∏è **Tempo:** 40-100h/m√™s economizadas (automa√ß√£o + best practices)
- üìö **Conhecimento:** Redu√ß√£o de 70% em "tempo para resolver problemas repetidos"
- üö® **Preven√ß√£o:** 5-15 incidents/m√™s evitados (alertas proativos)

**Pr√≥ximo Passo:**
‚Üí **M√≥dulo 5: DECIS√ÉO** (dashboards + automa√ß√£o de a√ß√µes)

---

*√öltima Atualiza√ß√£o: 2025-11-10*
